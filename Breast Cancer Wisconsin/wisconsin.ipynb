{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0dafacb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      Benign       0.96      1.00      0.98        72\n",
      "   Malignant       1.00      0.93      0.96        42\n",
      "\n",
      "    accuracy                           0.97       114\n",
      "   macro avg       0.98      0.96      0.97       114\n",
      "weighted avg       0.97      0.97      0.97       114\n",
      "\n",
      "Accuracy: 0.9737\n",
      "ROC-AUC: 0.994\n",
      "\n",
      "✅ Exported:\n",
      " - models\\Wisconsin\\wisconsin.xgb.json\n",
      " - models\\Wisconsin\\wisconsin.xgb.ubj\n",
      " - models\\Wisconsin\\ref_columns.json\n",
      " - models\\Wisconsin\\scaling_info.json\n",
      " - models\\Wisconsin\\target_name.txt\n",
      " - models\\Wisconsin\\metadata.json\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Breast Cancer Wisconsin (Diagnostic) — XGBoost + Exports\n",
    "\n",
    "import os, json, hashlib\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import (\n",
    "    classification_report, accuracy_score, roc_auc_score\n",
    ")\n",
    "import xgboost as xgb\n",
    "\n",
    "# -----------------\n",
    "# Paths and configuration\n",
    "# -----------------\n",
    "DATA_PATH = \"data/data.csv\"\n",
    "TARGET_NAME = \"diagnosis\"\n",
    "EXPORT_DIR = Path(\"models/Wisconsin\")\n",
    "\n",
    "EXPORT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "MODEL_JSON = EXPORT_DIR / \"wisconsin.xgb.json\"\n",
    "MODEL_UBJ  = EXPORT_DIR / \"wisconsin.xgb.ubj\"\n",
    "REF_COLS   = EXPORT_DIR / \"ref_columns.json\"\n",
    "SCALING    = EXPORT_DIR / \"scaling_info.json\"\n",
    "TARGET_TXT = EXPORT_DIR / \"target_name.txt\"\n",
    "META_JSON  = EXPORT_DIR / \"metadata.json\"\n",
    "\n",
    "# -----------------\n",
    "# Load dataset and preprocess\n",
    "# -----------------\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "# Drop columns that are not useful if they exist\n",
    "df = df.drop(columns=[\"id\", \"Unnamed: 32\"], errors=\"ignore\")\n",
    "\n",
    "# Encode diagnosis: Malignant=1, Benign=0\n",
    "df[TARGET_NAME] = df[TARGET_NAME].map({\"M\": 1, \"B\": 0}).astype(int)\n",
    "\n",
    "feature_cols = [c for c in df.columns if c != TARGET_NAME]\n",
    "\n",
    "# -----------------\n",
    "# Feature scaling with MinMaxScaler\n",
    "# -----------------\n",
    "scaler = MinMaxScaler()\n",
    "X_all = df[feature_cols].copy()\n",
    "y_all = df[TARGET_NAME].copy()\n",
    "\n",
    "X_all_scaled = scaler.fit_transform(X_all)\n",
    "\n",
    "# -----------------\n",
    "# Split into train and test sets\n",
    "# -----------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_all_scaled, y_all, test_size=0.2, random_state=42, stratify=y_all\n",
    ")\n",
    "\n",
    "# -----------------\n",
    "# Train XGBoost model\n",
    "# -----------------\n",
    "pos, neg = int((y_train == 1).sum()), int((y_train == 0).sum())\n",
    "spw = float(neg) / float(pos) if pos > 0 else 1.0\n",
    "\n",
    "clf = xgb.XGBClassifier(\n",
    "    n_estimators=400,\n",
    "    max_depth=4,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.8,\n",
    "    objective=\"binary:logistic\",\n",
    "    eval_metric=\"auc\",\n",
    "    scale_pos_weight=spw,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    tree_method=\"hist\",\n",
    "    enable_categorical=False\n",
    ")\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# -----------------\n",
    "# Evaluate performance\n",
    "# -----------------\n",
    "y_prob = clf.predict_proba(X_test)[:, 1]\n",
    "y_pred = (y_prob >= 0.5).astype(int)\n",
    "\n",
    "print(\"\\nClassification Report:\\n\",\n",
    "      classification_report(y_test, y_pred, target_names=[\"Benign\",\"Malignant\"]))\n",
    "print(\"Accuracy:\", round(accuracy_score(y_test, y_pred), 4))\n",
    "print(\"ROC-AUC:\", round(roc_auc_score(y_test, y_prob), 4))\n",
    "\n",
    "# -----------------\n",
    "# Export model and metadata\n",
    "# -----------------\n",
    "clf.save_model(str(MODEL_JSON))\n",
    "\n",
    "# UBJSON export if available\n",
    "try:\n",
    "    clf.save_model(str(MODEL_UBJ))\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# Save feature column order\n",
    "REF_COLS.write_text(json.dumps(feature_cols, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "# Save scaling information (per-feature min and max from original data)\n",
    "scaling_info = {\n",
    "    col: {\"min\": float(X_all[col].min()), \"max\": float(X_all[col].max())}\n",
    "    for col in feature_cols\n",
    "}\n",
    "SCALING.write_text(json.dumps(scaling_info, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "# Save target column name\n",
    "TARGET_TXT.write_text(f\"{TARGET_NAME}\\n\", encoding=\"utf-8\")\n",
    "\n",
    "# Save metadata (versions and hashes)\n",
    "def _file_sha256(p: Path) -> str:\n",
    "    h = hashlib.sha256()\n",
    "    with open(p, \"rb\") as f:\n",
    "        for chunk in iter(lambda: f.read(1 << 20), b\"\"):\n",
    "            h.update(chunk)\n",
    "    return h.hexdigest()\n",
    "\n",
    "metadata = {\n",
    "    \"framework\": \"xgboost\",\n",
    "    \"xgboost_version\": xgb.__version__,\n",
    "    \"model_files\": {\n",
    "        \"json\": {\"path\": str(MODEL_JSON), \"sha256\": _file_sha256(MODEL_JSON)},\n",
    "        \"ubj\":  {\"path\": str(MODEL_UBJ),  \"exists\": MODEL_UBJ.exists()}\n",
    "    },\n",
    "    \"features\": feature_cols,\n",
    "    \"target\": TARGET_NAME,\n",
    "    \"scaler\": \"MinMaxScaler\",\n",
    "}\n",
    "META_JSON.write_text(json.dumps(metadata, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "print(\"\\nExported:\")\n",
    "for p in [MODEL_JSON, MODEL_UBJ, REF_COLS, SCALING, TARGET_TXT, META_JSON]:\n",
    "    if p.exists():\n",
    "        print(\" -\", p)\n",
    "\n",
    "\n",
    "df.info()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af1c4e66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 31 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   diagnosis                569 non-null    int64  \n",
      " 1   radius_mean              569 non-null    float64\n",
      " 2   texture_mean             569 non-null    float64\n",
      " 3   perimeter_mean           569 non-null    float64\n",
      " 4   area_mean                569 non-null    float64\n",
      " 5   smoothness_mean          569 non-null    float64\n",
      " 6   compactness_mean         569 non-null    float64\n",
      " 7   concavity_mean           569 non-null    float64\n",
      " 8   concave points_mean      569 non-null    float64\n",
      " 9   symmetry_mean            569 non-null    float64\n",
      " 10  fractal_dimension_mean   569 non-null    float64\n",
      " 11  radius_se                569 non-null    float64\n",
      " 12  texture_se               569 non-null    float64\n",
      " 13  perimeter_se             569 non-null    float64\n",
      " 14  area_se                  569 non-null    float64\n",
      " 15  smoothness_se            569 non-null    float64\n",
      " 16  compactness_se           569 non-null    float64\n",
      " 17  concavity_se             569 non-null    float64\n",
      " 18  concave points_se        569 non-null    float64\n",
      " 19  symmetry_se              569 non-null    float64\n",
      " 20  fractal_dimension_se     569 non-null    float64\n",
      " 21  radius_worst             569 non-null    float64\n",
      " 22  texture_worst            569 non-null    float64\n",
      " 23  perimeter_worst          569 non-null    float64\n",
      " 24  area_worst               569 non-null    float64\n",
      " 25  smoothness_worst         569 non-null    float64\n",
      " 26  compactness_worst        569 non-null    float64\n",
      " 27  concavity_worst          569 non-null    float64\n",
      " 28  concave points_worst     569 non-null    float64\n",
      " 29  symmetry_worst           569 non-null    float64\n",
      " 30  fractal_dimension_worst  569 non-null    float64\n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 137.9 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53d404ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement gxboost (from versions: none)\n",
      "ERROR: No matching distribution found for gxboost\n"
     ]
    }
   ],
   "source": [
    "pip install gxboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26cbe848",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
